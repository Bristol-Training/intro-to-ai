{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# How do neural networks learn?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "We have seen how you can prepare some data with features ``X`` and labels ``y``. Then we can define the architecture/structure of a multi-layer perceptron (MLP) and randomly initialise a collection of weights ``w`` and biases ``b`` for the different neurons and layers of our MLP. We can then feed our training data through our MLP to get predictions of our class labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "$X_{i} \\to MLP(w, b) \\to Prediction_{i}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "We have also seen that we can measure our sum of square errors by adding up the squared difference between each prediction and the corresponding observation (i.e. the correct answer). This sum will be ``0`` if our predictions are all correct and will get larger as more of our guesses are wrong. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "$Predictions, Observations \\to Error$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Tuning our weights and biases\n",
    "\n",
    "We saw that randomly initialising the weights and biases was unlikely to lead to good predictions. We want to tune our weights and biases in a way that reduces our error.\n",
    "\n",
    "The error is a function of our predictions and our observations. Our predictions are a function of our weights and biases. These statements together imply that our error is implicitly a function of our weights and biases. In other words:\n",
    "\n",
    "*Changing your weights and biases in your MLP will change your error.*\n",
    "\n",
    "For fixed data and network structure, we can try to understand how we can change our weights and biases to reduce our error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Gradient Descent in 1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LinearFunc(x, weight, bias):\n",
    "    \"\"\"\n",
    "    Linear function: y = weight * x + bias\n",
    "    \"\"\"\n",
    "    return weight * x + bias\n",
    "\n",
    "import math\n",
    "# Generate some sample data\n",
    "x = [i for i in range(10)]\n",
    "y = [math.sin(i) for i in x]\n",
    "\n",
    "def SSE(x, y, weight, bias):\n",
    "    \"\"\"\n",
    "    Calculate the sum of squared errors (SSE) for a linear model.\n",
    "    \"\"\"\n",
    "    return sum((y[i] - LinearFunc(x[i], weight, bias)) ** 2 for i in range(len(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix the bias but vary the weight\n",
    "bias = 2\n",
    "\n",
    "ErrorDict = {}\n",
    "for weight in range(-20, 20, 2):\n",
    "    sse = SSE(x, y, weight, bias)\n",
    "    ErrorDict[weight] = sse\n",
    "\n",
    "# Plot the error curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(ErrorDict.keys(), ErrorDict.values(), marker='o')\n",
    "plt.title('Sum of Squared Errors (SSE) vs. Weight (w1)')\n",
    "plt.xlabel('Weight')\n",
    "plt.ylabel('SSE')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "We can see for different weight values, there is a different error value. Accurate prediction is as simple as minimising the error with respect to the weights and biases.\n",
    "\n",
    "In a calculus class you might have taken the derivative of a function $\\frac{dError}{dWeight}$, which represents the slope/gradient of the error function with respect to the weight at a given position. \n",
    "\n",
    "Whilst you could in theory solve for when the derivative/slope is zero, to find an explicit answer in situations where there are a large number of weights and biases is often intractably difficult.\n",
    "\n",
    "Instead, we understand that if the derivative is positive when the slope is upwards and negative when the slope is downwards, we can just head in the opposite direction of the derivative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DerivativeSSE(x, y, weight, bias):\n",
    "    \"\"\"\n",
    "    Calculate the derivative of SSE with respect to weight.\n",
    "    \"\"\"\n",
    "    return -2 * sum((y[i] - LinearFunc(x[i], weight, bias)) * x[i] for i in range(len(y))) / len(y)\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(1, 2)\n",
    "\n",
    "# Plot SSE\n",
    "axes[0].plot(ErrorDict.keys(), ErrorDict.values(), marker='o')\n",
    "axes[0].set_title('SSE vs. Weight (w1)')\n",
    "axes[0].set_xlabel('Weight (w1)')\n",
    "axes[0].set_ylabel('SSE')\n",
    "axes[0].grid(True)\n",
    "\n",
    "# Plot Derivative of SSE\n",
    "axes[1].plot(ErrorDict.keys(), [DerivativeSSE(x, y, weight, bias) for weight in ErrorDict.keys()], marker='o')\n",
    "axes[1].set_title('Derivative of SSE vs. Weight (w1)')\n",
    "axes[1].set_xlabel('Weight (w1)')\n",
    "axes[1].set_ylabel('d(SSE)/dw1')\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Make wider Huw!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "Consider the above left plot and choose a position on the x-axis and look at its corresponding SSE value. You can intuitively see which way is \"downhill\". \n",
    "\n",
    "On the above right plot you should be able to read off the derivative at the same x-axis value. If the left plot shows you're facing uphill, the derivative should be positive on the right plot. If you're facing downhill the derivative should be negative. The larger the value of the derivative, the steeper the slope.\n",
    "\n",
    "It make sense then that we should take a step in the direction of the negative of the gradient. You should take a larger step if the value of the derivative is larger. \n",
    "\n",
    "In practise we take a step size proportional to the derivative. We call the constant of proportionality the *learning rate*. If the learning rate is too large we might step over a minimum. If the rate is too small then we might take too long to find the minimum!\n",
    "\n",
    "The process of taking small steps downhill by varying our weights is called *Gradient Descent*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Gradient Descent in Higher Dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "In practise, we want to update all the weights and biases of our neural network at once. This means we want to use a generalisation of the derivative called the gradient function. Given a function $f$ of $n$ variables: $w_{1}, w_{2}, \\ldots, w_{n}$ we can define the gradient function of $f$ as:\n",
    "\n",
    "$\\nabla f (w_{1}, \\ldots, w_{n}) = \\begin{bmatrix}\n",
    "           \\frac{\\partial f}{\\partial w_{1}} \\\\\n",
    "           \\frac{\\partial f}{\\partial w_{2}} \\\\\n",
    "           \\vdots \\\\\n",
    "           \\frac{\\partial f}{\\partial w_{n}}\n",
    "         \\end{bmatrix}  $\n",
    "\n",
    "where $\\frac{\\partial f}{\\partial w_{1}}$ is the *partial derivative* of the function $f$ with respect to $w_{1}$. What this means is that each component of this vector tells you how steep the function $f$ is with respect to each of its variables.\n",
    "\n",
    "Now if we imagine a loss surface (like a mountain range where the height of where you are standing is the value of a loss function) then we just want to walk downhill with respect to all of our components. This direction is described by the gradient vector.\n",
    "\n",
    "In practise the step we take is proportional to the size of the gradient. We will define a variable called the *learning rate*, which will tell us how big of a step to take downhill each time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "You can play around with this web app to see how the loss surface \"looks\" with respect to a function and see how gradient descent moves you downhill towards minimal loss \n",
    "\n",
    "https://neuralpatterns.io/hill_climber.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
